"""
Advanced ML-based vulnerability detection using transformer models
"""

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel, AutoConfig
import numpy as np
from typing import List, Dict, Any, Tuple
import re
import ast
import logging
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import pickle
import os
import json
from datetime import datetime

class CodeBERTVulnerabilityDetector:
    """
    Advanced vulnerability detector using CodeBERT and ensemble methods
    """
    
    def __init__(self, model_path: str = None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_name = model_path or 'microsoft/codebert-base'
        self.max_length = 512
        self.confidence_threshold = 0.7
        
        # Initialize tokenizer and model
        self.tokenizer = None
        self.model = None
        self.classifier = None
        
        # Vulnerability categories based on OWASP Top 10 and CWE
        self.vulnerability_categories = {
            'injection': ['sql_injection', 'command_injection', 'ldap_injection'],
            'broken_auth': ['weak_auth', 'session_fixation', 'credential_exposure'],
            'sensitive_exposure': ['data_exposure', 'hardcoded_secrets', 'logging_sensitive'],
            'xxe': ['xml_external_entity', 'xml_injection'],
            'broken_access': ['path_traversal', 'privilege_escalation', 'idor'],
            'security_misconfig': ['default_config', 'debug_enabled', 'unnecessary_features'],
            'xss': ['reflected_xss', 'stored_xss', 'dom_xss'],
            'insecure_deserialization': ['unsafe_deserialization', 'object_injection'],
            'vulnerable_components': ['outdated_libraries', 'known_vulnerabilities'],
            'insufficient_logging': ['missing_logs', 'inadequate_monitoring']
        }
        
        # Load or initialize models
        self._initialize_models()
    
    def _initialize_models(self):
        """Initialize CodeBERT and ensemble models"""
        try:
            # Initialize CodeBERT tokenizer and model
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModel.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()
            
            # Initialize ensemble classifier
            self.classifier = VotingClassifier(
                estimators=[
                    ('lr', LogisticRegression(random_state=42)),
                    ('dt', DecisionTreeClassifier(random_state=42)),
                    ('svm', SVC(probability=True, random_state=42))
                ],
                voting='soft'
            )
            
            logging.info(f"Initialized ML models on device: {self.device}")
            
        except Exception as e:
            logging.error(f"Failed to initialize ML models: {e}")
            # Fallback to pattern-based detection
            self.model = None
            self.tokenizer = None
    
    def extract_code_features(self, code: str) -> Dict[str, Any]:
        """Extract traditional features from code for ensemble learning"""
        features = {}
        
        # Basic code metrics
        lines = code.split('\n')
        features['line_count'] = len(lines)
        features['char_count'] = len(code)
        features['avg_line_length'] = np.mean([len(line) for line in lines])
        
        # Complexity metrics
        features['cyclomatic_complexity'] = self._calculate_cyclomatic_complexity(code)
        features['nesting_depth'] = self._calculate_nesting_depth(code)
        
        # Security-relevant patterns
        features['has_eval'] = 1 if re.search(r'\beval\s*\(', code, re.IGNORECASE) else 0
        features['has_exec'] = 1 if re.search(r'\bexec\s*\(', code, re.IGNORECASE) else 0
        features['has_sql_patterns'] = 1 if re.search(r'(SELECT|INSERT|UPDATE|DELETE).*WHERE', code, re.IGNORECASE) else 0
        features['has_file_operations'] = 1 if re.search(r'(open|read|write|file)', code, re.IGNORECASE) else 0
        features['has_network_calls'] = 1 if re.search(r'(http|url|request|socket)', code, re.IGNORECASE) else 0
        features['has_crypto_operations'] = 1 if re.search(r'(encrypt|decrypt|hash|cipher)', code, re.IGNORECASE) else 0
        
        # String and input handling
        features['string_concatenation_count'] = len(re.findall(r'\+\s*["\']', code))
        features['format_string_count'] = len(re.findall(r'%[sd]|\.format\(|\{.*?\}', code))
        features['input_function_count'] = len(re.findall(r'\binput\s*\(|\braw_input\s*\(', code))
        
        # Error handling
        features['try_catch_count'] = len(re.findall(r'\btry\s*:', code, re.IGNORECASE))
        features['exception_handling'] = 1 if re.search(r'except|catch|finally', code, re.IGNORECASE) else 0
        
        return features
    
    def _calculate_cyclomatic_complexity(self, code: str) -> int:
        """Calculate cyclomatic complexity of code"""
        complexity = 1  # Base complexity
        
        # Count decision points
        decision_keywords = ['if', 'elif', 'else', 'for', 'while', 'try', 'except', 'finally', 'with']
        for keyword in decision_keywords:
            complexity += len(re.findall(rf'\b{keyword}\b', code, re.IGNORECASE))
        
        # Count logical operators
        complexity += len(re.findall(r'\band\b|\bor\b|&&|\|\|', code, re.IGNORECASE))
        
        return min(complexity, 50)  # Cap at reasonable maximum
    
    def _calculate_nesting_depth(self, code: str) -> int:
        """Calculate maximum nesting depth"""
        max_depth = 0
        current_depth = 0
        
        for line in code.split('\n'):
            stripped = line.strip()
            if not stripped or stripped.startswith('#'):
                continue
            
            # Count opening braces/blocks
            if any(keyword in stripped for keyword in ['if ', 'for ', 'while ', 'try:', 'with ', 'def ', 'class ']):
                current_depth += 1
                max_depth = max(max_depth, current_depth)
            
            # Count closing (simplified - based on indentation decrease)
            if stripped in ['end', '}'] or (len(line) - len(line.lstrip()) == 0 and stripped):
                current_depth = max(0, current_depth - 1)
        
        return min(max_depth, 20)  # Cap at reasonable maximum
    
    def get_code_embeddings(self, code: str) -> np.ndarray:
        """Get CodeBERT embeddings for code"""
        if not self.model or not self.tokenizer:
            return np.zeros(768)  # Return zero vector if model not available
        
        try:
            # Tokenize code
            inputs = self.tokenizer(
                code,
                return_tensors='pt',
                max_length=self.max_length,
                truncation=True,
                padding=True
            )
            
            # Move to device
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # Get embeddings
            with torch.no_grad():
                outputs = self.model(**inputs)
                # Use CLS token embedding
                embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
            
            return embeddings.flatten()
            
        except Exception as e:
            logging.error(f"Failed to get code embeddings: {e}")
            return np.zeros(768)
    
    def detect_vulnerabilities(self, code: str, language: str = 'python') -> List[Dict[str, Any]]:
        """
        Detect vulnerabilities using ML models
        """
        vulnerabilities = []
        
        try:
            # Extract traditional features
            traditional_features = self.extract_code_features(code)
            
            # Get CodeBERT embeddings
            code_embeddings = self.get_code_embeddings(code)
            
            # Combine features
            combined_features = np.concatenate([
                list(traditional_features.values()),
                code_embeddings
            ])
            
            # Predict vulnerabilities (if classifier is trained)
            if hasattr(self.classifier, 'predict_proba'):
                try:
                    # Reshape for single sample prediction
                    features_reshaped = combined_features.reshape(1, -1)
                    
                    # Get vulnerability probabilities
                    vulnerability_probs = self.classifier.predict_proba(features_reshaped)[0]
                    
                    # Convert to vulnerability predictions
                    for i, prob in enumerate(vulnerability_probs):
                        if prob > self.confidence_threshold:
                            vulnerability_type = list(self.vulnerability_categories.keys())[i % len(self.vulnerability_categories)]
                            
                            vulnerability = {
                                'id': f'ML_{vulnerability_type}_{hash(code) % 10000}',
                                'type': vulnerability_type.upper(),
                                'severity': self._get_severity_from_probability(prob),
                                'confidence': float(prob),
                                'description': f'ML model detected potential {vulnerability_type.replace("_", " ")} vulnerability',
                                'recommendation': self._get_recommendation(vulnerability_type),
                                'ml_features': traditional_features,
                                'embedding_similarity': float(np.max(code_embeddings)) if len(code_embeddings) > 0 else 0.0,
                                'timestamp': datetime.utcnow().isoformat()
                            }
                            vulnerabilities.append(vulnerability)
                
                except Exception as e:
                    logging.warning(f"Classifier prediction failed: {e}")
            
            # Fallback to pattern-based detection with ML enhancement
            pattern_vulnerabilities = self._pattern_based_detection_with_ml(code, traditional_features)
            vulnerabilities.extend(pattern_vulnerabilities)
            
        except Exception as e:
            logging.error(f"ML vulnerability detection failed: {e}")
            # Fallback to basic pattern detection
            vulnerabilities = self._basic_pattern_detection(code)
        
        return vulnerabilities
    
    def _pattern_based_detection_with_ml(self, code: str, features: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Enhanced pattern-based detection using ML features"""
        vulnerabilities = []
        
        # SQL Injection detection with context
        if features['has_sql_patterns'] and (features['string_concatenation_count'] > 0 or features['format_string_count'] > 0):
            sql_patterns = [
                r'execute\s*\(\s*["\'].*%.*["\']',
                r'query\s*\(\s*["\'].*\+.*["\']',
                r'(SELECT|INSERT|UPDATE|DELETE).*\+.*WHERE'
            ]
            
            for pattern in sql_patterns:
                if re.search(pattern, code, re.IGNORECASE):
                    vulnerabilities.append({
                        'id': f'ML_SQL_INJ_{hash(code) % 10000}',
                        'type': 'SQL_INJECTION',
                        'severity': 'CRITICAL',
                        'confidence': 0.85,
                        'description': 'ML-enhanced detection of SQL injection vulnerability',
                        'recommendation': 'Use parameterized queries or prepared statements',
                        'pattern_matched': pattern,
                        'context_features': features
                    })
        
        # XSS detection with context
        if features['has_network_calls'] and features['string_concatenation_count'] > 2:
            xss_patterns = [
                r'render_template_string\s*\(.*\+',
                r'innerHTML\s*=.*\+',
                r'document\.write\s*\(.*\+'
            ]
            
            for pattern in xss_patterns:
                if re.search(pattern, code, re.IGNORECASE):
                    vulnerabilities.append({
                        'id': f'ML_XSS_{hash(code) % 10000}',
                        'type': 'XSS',
                        'severity': 'HIGH',
                        'confidence': 0.80,
                        'description': 'ML-enhanced detection of XSS vulnerability',
                        'recommendation': 'Use proper output encoding and CSP headers',
                        'pattern_matched': pattern,
                        'context_features': features
                    })
        
        # Command injection with complexity analysis
        if features['has_exec'] or features['has_eval']:
            if features['cyclomatic_complexity'] > 5 and features['input_function_count'] > 0:
                vulnerabilities.append({
                    'id': f'ML_CMD_INJ_{hash(code) % 10000}',
                    'type': 'COMMAND_INJECTION',
                    'severity': 'CRITICAL',
                    'confidence': 0.90,
                    'description': 'ML-enhanced detection of command injection vulnerability',
                    'recommendation': 'Avoid dynamic code execution with user input',
                    'complexity_score': features['cyclomatic_complexity'],
                    'context_features': features
                })
        
        return vulnerabilities
    
    def _basic_pattern_detection(self, code: str) -> List[Dict[str, Any]]:
        """Basic pattern-based detection as fallback"""
        vulnerabilities = []
        
        basic_patterns = [
            {
                'pattern': r'(password|secret|key|token)\s*=\s*["\'][^"\']{8,}["\']',
                'type': 'HARDCODED_SECRET',
                'severity': 'HIGH',
                'description': 'Hardcoded secret detected'
            },
            {
                'pattern': r'eval\s*\(',
                'type': 'CODE_INJECTION',
                'severity': 'CRITICAL',
                'description': 'Use of eval() function'
            },
            {
                'pattern': r'exec\s*\(',
                'type': 'CODE_INJECTION',
                'severity': 'CRITICAL',
                'description': 'Use of exec() function'
            }
        ]
        
        lines = code.split('\n')
        for line_num, line in enumerate(lines, 1):
            for pattern_info in basic_patterns:
                if re.search(pattern_info['pattern'], line, re.IGNORECASE):
                    vulnerabilities.append({
                        'id': f'BASIC_{pattern_info["type"]}_{line_num}',
                        'type': pattern_info['type'],
                        'severity': pattern_info['severity'],
                        'confidence': 0.70,
                        'line': line_num,
                        'description': pattern_info['description'],
                        'recommendation': 'Review and secure this code pattern',
                        'matched_text': line.strip()
                    })
        
        return vulnerabilities
    
    def _get_severity_from_probability(self, probability: float) -> str:
        """Convert probability to severity level"""
        if probability >= 0.9:
            return 'CRITICAL'
        elif probability >= 0.7:
            return 'HIGH'
        elif probability >= 0.5:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _get_recommendation(self, vulnerability_type: str) -> str:
        """Get recommendation based on vulnerability type"""
        recommendations = {
            'injection': 'Use parameterized queries and input validation',
            'broken_auth': 'Implement strong authentication and session management',
            'sensitive_exposure': 'Encrypt sensitive data and use secure storage',
            'xxe': 'Disable XML external entity processing',
            'broken_access': 'Implement proper access controls and authorization',
            'security_misconfig': 'Review and harden security configurations',
            'xss': 'Use output encoding and Content Security Policy',
            'insecure_deserialization': 'Validate and sanitize serialized data',
            'vulnerable_components': 'Update to latest secure versions',
            'insufficient_logging': 'Implement comprehensive logging and monitoring'
        }
        
        return recommendations.get(vulnerability_type, 'Review code for security issues')
    
    def train_classifier(self, training_data: List[Dict[str, Any]]):
        """Train the ensemble classifier on labeled data"""
        if not training_data:
            logging.warning("No training data provided")
            return
        
        try:
            # Prepare training features and labels
            X = []
            y = []
            
            for sample in training_data:
                code = sample['code']
                is_vulnerable = sample['is_vulnerable']
                
                # Extract features
                traditional_features = self.extract_code_features(code)
                code_embeddings = self.get_code_embeddings(code)
                
                # Combine features
                combined_features = np.concatenate([
                    list(traditional_features.values()),
                    code_embeddings
                ])
                
                X.append(combined_features)
                y.append(1 if is_vulnerable else 0)
            
            X = np.array(X)
            y = np.array(y)
            
            # Train classifier
            self.classifier.fit(X, y)
            
            logging.info(f"Trained classifier on {len(training_data)} samples")
            
        except Exception as e:
            logging.error(f"Failed to train classifier: {e}")
    
    def save_model(self, path: str):
        """Save trained models"""
        try:
            model_data = {
                'classifier': self.classifier,
                'confidence_threshold': self.confidence_threshold,
                'vulnerability_categories': self.vulnerability_categories
            }
            
            with open(path, 'wb') as f:
                pickle.dump(model_data, f)
            
            logging.info(f"Saved ML models to {path}")
            
        except Exception as e:
            logging.error(f"Failed to save models: {e}")
    
    def load_model(self, path: str):
        """Load trained models"""
        try:
            with open(path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.classifier = model_data['classifier']
            self.confidence_threshold = model_data['confidence_threshold']
            self.vulnerability_categories = model_data['vulnerability_categories']
            
            logging.info(f"Loaded ML models from {path}")
            
        except Exception as e:
            logging.error(f"Failed to load models: {e}")

class GraphNeuralNetworkDetector:
    """
    Graph Neural Network-based vulnerability detector for structural code analysis
    """
    
    def __init__(self):
        self.node_features = {}
        self.edge_features = {}
        self.vulnerability_patterns = {}
    
    def build_code_graph(self, code: str) -> Dict[str, Any]:
        """Build code property graph from source code"""
        try:
            # Parse AST
            tree = ast.parse(code)
            
            # Build graph representation
            graph = {
                'nodes': [],
                'edges': [],
                'node_features': {},
                'edge_features': {}
            }
            
            # Extract nodes and edges from AST
            for node in ast.walk(tree):
                node_id = id(node)
                node_type = type(node).__name__
                
                graph['nodes'].append(node_id)
                graph['node_features'][node_id] = {
                    'type': node_type,
                    'line': getattr(node, 'lineno', 0),
                    'col': getattr(node, 'col_offset', 0)
                }
                
                # Add edges for child relationships
                for child in ast.iter_child_nodes(node):
                    child_id = id(child)
                    graph['edges'].append((node_id, child_id))
                    graph['edge_features'][(node_id, child_id)] = {
                        'type': 'child_of',
                        'weight': 1.0
                    }
            
            return graph
            
        except Exception as e:
            logging.error(f"Failed to build code graph: {e}")
            return {'nodes': [], 'edges': [], 'node_features': {}, 'edge_features': {}}
    
    def analyze_graph_vulnerabilities(self, graph: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Analyze graph for structural vulnerabilities"""
        vulnerabilities = []
        
        # Analyze for common vulnerability patterns in graph structure
        # This is a simplified implementation - real GNN would use trained models
        
        # Look for dangerous function call patterns
        dangerous_calls = ['eval', 'exec', 'compile']
        for node_id, features in graph['node_features'].items():
            if features['type'] == 'Call':
                # Check if this is a dangerous function call
                # In real implementation, would analyze the full call context
                vulnerabilities.append({
                    'id': f'GNN_DANGEROUS_CALL_{node_id}',
                    'type': 'DANGEROUS_FUNCTION_CALL',
                    'severity': 'HIGH',
                    'confidence': 0.75,
                    'line': features['line'],
                    'description': 'Graph analysis detected potentially dangerous function call',
                    'recommendation': 'Review function call for security implications',
                    'graph_features': features
                })
        
        return vulnerabilities

# Factory function to create appropriate detector
def create_vulnerability_detector(detector_type: str = 'codebert') -> Any:
    """Create vulnerability detector based on type"""
    if detector_type.lower() == 'codebert':
        return CodeBERTVulnerabilityDetector()
    elif detector_type.lower() == 'gnn':
        return GraphNeuralNetworkDetector()
    else:
        return CodeBERTVulnerabilityDetector()  # Default to CodeBERT

